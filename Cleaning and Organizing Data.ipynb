{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Pandas and Rename the Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "benchmark_data = pd.read_csv('sklearn-benchmark-data.tsv.gz', sep='\\t')\n",
    "benchmark_data.head()\n",
    "benchmark_data.rename(columns={'heart-c':'Dataset_Name',\n",
    "                               'GradientBoostingClassifier':'Method_Name',\n",
    "                               'loss=exponential,learning_rate=10.0,n_estimators=100,max_depth=3,max_features=sqrt,warm_start=True':'Parameters',\n",
    "                               '0.723684210526':'Test_Score'},inplace=True)\n",
    "\n",
    "#benchmark_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "benchmark_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "benchmark_data.boxplot('Test_Score', by='Parameters')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all the methods so as to divide the dataset into multiple dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names_list=benchmark_data['Dataset_Name'].unique().tolist()\n",
    "methods_list=benchmark_data['Method_Name'].unique().tolist()\n",
    "#names_list\n",
    "#methods_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(methods_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the dataframe into multiple dataframes by the method name\n",
    "methods_list=benchmark_data['Method_Name'].unique().tolist()\n",
    "MethodWiseData={}\n",
    "for method_name in methods_list:\n",
    "    MethodWiseData[method_name] = benchmark_data[benchmark_data.Method_Name==method_name]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a folder to save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a folder and save a file\n",
    "import os\n",
    "if not os.path.isdir('HPCC_Benchmark_Results'):\n",
    "    os.mkdir('HPCC_Benchmark_Results') \n",
    "\n",
    "MethodWiseData['LogisticRegression'].to_pickle('HPCC_Benchmark_Results/LogisticRegression.tsv.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To read the file\n",
    "# QUESTION: Why does it not work with csv.read\n",
    "Method_Type = pd.read_pickle('HPCC_Benchmark_Results/LogisticRegression.tsv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To run the code for all parameters, it is required to change in the above section the method name appropriately. Also below the number of parameters have to be inputted approprietly and the parameter name has to be changed as well to achieve the data cleaning for all methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Parameters columns (Every method has different number of parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Param_Split = pd.DataFrame(Method_Type.Parameters.str.split(',').tolist(),\n",
    "                                   columns = ['Param1','Param2'])\n",
    "#Param_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Method_Type1 = Method_Type.drop('Parameters', 1)    #delete the Parameters column from the original dataframe\n",
    "index = Param_Split.index.get_values()              #get the index of the parameter dataframe  \n",
    "Method_Type2 = Method_Type1.set_index(index)          #set the index of method dataframe same as parameter dataframe\n",
    "result = pd.concat([Method_Type2, Param_Split], axis = 1)    #finally add the parameter columns to get the result (desired format)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the Parameter Column to process it further and have only numeric values in it\n",
    "data_split1 = pd.DataFrame(result.Param1.str.split('=').tolist(),\n",
    "                                   columns = ['Param_Name','C'])\n",
    "data_split2 = pd.DataFrame(result.Param2.str.split('=').tolist(),\n",
    "                                   columns = ['Param_Name','penalty'])\n",
    "#data_split3 = pd.DataFrame(result.Param3.str.split('=').tolist(),\n",
    "#                                   columns = ['Param_Name','criterion'])\n",
    "#data_split4 = pd.DataFrame(result.Param4.str.split('=').tolist(),\n",
    "#                                   columns = ['Param_Name','kernel'])\n",
    "#data_split5 = pd.DataFrame(result.Param5.str.split('=').tolist(),\n",
    "#                                   columns = ['Param_Name','degree'])\n",
    "#data_split6 = pd.DataFrame(result.Param5.str.split('=').tolist(),\n",
    "#                                   columns = ['Param_Name','warm_start'])\n",
    "\n",
    "# Delete the Parameters column from the original dataframe\n",
    "method_data1 = result.drop('Param1',1)  \n",
    "method_data1 = method_data1.drop('Param2',1)\n",
    "#method_data1 = method_data1.drop('Param3',1)\n",
    "#method_data1 = method_data1.drop('Param4',1)\n",
    "#method_data1 = method_data1.drop('Param5',1)\n",
    "#method_data1 = method_data1.drop('Param6',1)\n",
    "\n",
    "data_split1 = data_split1.drop('Param_Name',1)\n",
    "data_split2 = data_split2.drop('Param_Name',1)\n",
    "#data_split3 = data_split3.drop('Param_Name',1)\n",
    "#data_split4 = data_split4.drop('Param_Name',1)\n",
    "#data_split5 = data_split5.drop('Param_Name',1)\n",
    "#data_split6 = data_split6.drop('Param_Name',1)\n",
    "\n",
    "idx = data_split1.index.get_values()               #get the index of the parameter dataframe  \n",
    "method_data2 = method_data1.set_index(idx)         #set the index of method dataframe same as parameter dataframe\n",
    "cleaned_data = pd.concat([method_data2, data_split1, data_split2], axis = 1)\n",
    "#finally add the parameter columns to get the result (desired format)\n",
    "\n",
    "# You must cast the data as a float type -- it was parsed into a string type\n",
    "#cleaned_data['n_estimators'] = cleaned_data['n_estimators'].astype(float)\n",
    "#cleaned_data['learning_rate'] = cleaned_data['learning_rate'].astype(float)\n",
    "#cleaned_data['warm_start'] = cleaned_data['warm_start'].astype(float)\n",
    "#cleaned_data['criterion'] = cleaned_data['criterion'].astype(float)\n",
    "#cleaned_data['warm_start'] = cleaned_data['warm_start'].astype(float)\n",
    "\n",
    "#cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save this file of a method and parameters organized in columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('Cleaned_Method_Wise_Data'):\n",
    "    os.mkdir('Cleaned_Method_Wise_Data')\n",
    "cleaned_data.to_pickle('Cleaned_Method_Wise_Data/LogisticRegression_cleaned.tsv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the file\n",
    "Cleaned_Data = pd.read_pickle('Cleaned_Method_Wise_Data/LogisticRegression_cleaned.tsv.gz')\n",
    "#Cleaned_Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
